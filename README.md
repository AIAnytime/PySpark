
## Introduction to PySpark

- **Spark** is a unified analytics engine for **large-scale data preprocessing.**
- PySpark is just a **python wrapper around the Spark**.

![PySpark](https://databricks.com/wp-content/uploads/2018/12/PySpark-1024x164.png)

Let's c the Spark Ecosystem by a below example:
![Spark](https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/08/14133246/Image-recreation-for-articles-A4-06-1-1024x578.jpg)

Key Data Structures in the Spark API:
**RDD (Resilient Distributed dataset) :- Transformations and Actions**

PySpark:

- 1. PySpark.ML (Dataframe, Current)
- 2. PySpark.MLlib (RDD, legacy)

![PySpark Pipeline](https://intellipaat.com/mediaFiles/2019/02/MLlib-algorithms.png)
